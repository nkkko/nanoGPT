step 0: train loss 4.2882, val loss 4.2822
iter 0: loss 4.2672, time 28319.72ms, mfu -100.00%
iter 10: loss 3.2323, time 45.79ms, mfu 4.07%
iter 20: loss 2.8204, time 45.30ms, mfu 4.07%
iter 30: loss 2.6505, time 43.81ms, mfu 4.09%
iter 40: loss 2.5816, time 44.57ms, mfu 4.10%
iter 50: loss 2.5451, time 47.07ms, mfu 4.09%
iter 60: loss 2.5283, time 44.22ms, mfu 4.10%
iter 70: loss 2.5141, time 46.41ms, mfu 4.09%
iter 80: loss 2.5048, time 44.27ms, mfu 4.10%
iter 90: loss 2.4504, time 48.68ms, mfu 4.07%
iter 100: loss 2.4669, time 45.70ms, mfu 4.07%
iter 110: loss 2.4609, time 47.00ms, mfu 4.06%
iter 120: loss 2.4984, time 45.84ms, mfu 4.06%
iter 130: loss 2.4574, time 47.29ms, mfu 4.05%
iter 140: loss 2.4279, time 47.20ms, mfu 4.04%
iter 150: loss 2.4533, time 47.40ms, mfu 4.03%
iter 160: loss 2.4333, time 46.39ms, mfu 4.03%
iter 170: loss 2.4310, time 46.56ms, mfu 4.03%
iter 180: loss 2.4057, time 47.91ms, mfu 4.01%
iter 190: loss 2.3853, time 46.80ms, mfu 4.01%
iter 200: loss 2.3646, time 46.35ms, mfu 4.01%
iter 210: loss 2.3458, time 45.21ms, mfu 4.02%
iter 220: loss 2.3128, time 45.74ms, mfu 4.03%
iter 230: loss 2.3108, time 46.22ms, mfu 4.03%
iter 240: loss 2.2834, time 45.91ms, mfu 4.03%
step 250: train loss 2.1660, val loss 2.2255
saving checkpoint to out-shakespeare-char
iter 250: loss 2.2102, time 5981.12ms, mfu 3.63%
iter 260: loss 2.1886, time 44.51ms, mfu 3.69%
iter 270: loss 2.1282, time 45.31ms, mfu 3.73%
iter 280: loss 2.1558, time 43.85ms, mfu 3.78%
iter 290: loss 2.1108, time 44.43ms, mfu 3.82%
iter 300: loss 2.1123, time 46.77ms, mfu 3.84%
iter 310: loss 2.0947, time 44.37ms, mfu 3.87%
iter 320: loss 2.0419, time 46.18ms, mfu 3.89%
iter 330: loss 2.0458, time 46.27ms, mfu 3.90%
iter 340: loss 2.0198, time 48.64ms, mfu 3.90%
iter 350: loss 2.0069, time 47.09ms, mfu 3.90%
iter 360: loss 1.9936, time 47.74ms, mfu 3.90%
iter 370: loss 1.9580, time 45.08ms, mfu 3.93%
iter 380: loss 1.9131, time 45.93ms, mfu 3.94%
iter 390: loss 1.9310, time 45.43ms, mfu 3.95%
iter 400: loss 1.8918, time 46.93ms, mfu 3.96%
iter 410: loss 1.8864, time 47.97ms, mfu 3.95%
iter 420: loss 1.8711, time 47.88ms, mfu 3.94%
iter 430: loss 1.8439, time 47.22ms, mfu 3.94%
iter 440: loss 1.8495, time 46.99ms, mfu 3.95%
iter 450: loss 1.8995, time 47.17ms, mfu 3.95%
iter 460: loss 1.7940, time 47.09ms, mfu 3.95%
iter 470: loss 1.8451, time 47.43ms, mfu 3.95%
iter 480: loss 1.8173, time 47.04ms, mfu 3.95%
iter 490: loss 1.7549, time 46.06ms, mfu 3.96%
Traceback (most recent call last):
  File "/workspaces/nanoGPT/train.py", line 264, in <module>
    losses = estimate_loss()
  File "/home/codeany/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/workspaces/nanoGPT/train.py", line 225, in estimate_loss
    losses[k] = loss.item()
KeyboardInterrupt
